{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import time\n",
    "import pickle\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_file(filepath):\n",
    "    \n",
    "    with open(filepath, 'r') as f:\n",
    "        file = f.readlines()\n",
    "    return file\n",
    "\n",
    "src_file = load_file('data/file.de')\n",
    "trg_file = load_file('data/file.en')\n",
    "aligned_file = load_file('data/file.aligned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract(trg_start, trg_end, src_start, src_end, alignments, trg_aligned, trg_len):    \n",
    "\n",
    "    if trg_end < 0 :\n",
    "        return [], []\n",
    "    \n",
    "    A = []\n",
    "    \n",
    "    a = []\n",
    "    \n",
    "    for trg_word, src_word  in alignments:\n",
    "        if trg_start <= trg_word <= trg_end:\n",
    "            \n",
    "            if (src_word < src_start or src_word > src_end):  \n",
    "                return [], []\n",
    "            else:\n",
    "                \n",
    "                a.append( (trg_word - trg_start, src_word - src_start) )\n",
    "\n",
    "    E = []\n",
    "    trg_s = trg_start\n",
    "    \n",
    "    while True:\n",
    "        trg_e = trg_end\n",
    "        while True:\n",
    "            E.append( (\" \".join(trg_words[trg_s:trg_e+1]) , \" \".join(src_words[src_start:src_end+1]) ))\n",
    "            \n",
    "            A.append(a)\n",
    "             \n",
    "            trg_e += 1\n",
    "            \n",
    "            if trg_e in trg_aligned or trg_e == len(trg_words):\n",
    "                break \n",
    "\n",
    "        trg_s -= 1\n",
    "        \n",
    "        if trg_s in trg_aligned or trg_s < 0:\n",
    "            break\n",
    "       \n",
    "        a = [(i[0]+1,i[1]) for i in a]\n",
    "        \n",
    "    return E, A\n",
    "\n",
    "\n",
    "def extract_phrases(src_words, trg_words, alignments, cutoff):\n",
    "    \n",
    "    \n",
    "    if cutoff == -1:\n",
    "        cutoff = len(src_words)\n",
    "        \n",
    "        \n",
    "    trg_aligned = set()\n",
    "    for (trg,_) in alignments:\n",
    "        trg_aligned.add(trg)\n",
    "    \n",
    "    \n",
    "    extracted_phrases = []\n",
    "    extracted_alignments = []\n",
    "    for src_start in range(len(src_words)):\n",
    "        for src_end in range(src_start, min(src_start + cutoff, len(src_words))):\n",
    "\n",
    "            trg_start = len(trg_words) - 1\n",
    "            trg_end = - 1\n",
    "            for  (trg,src) in alignments: \n",
    "                if src_start <= src <= src_end:\n",
    "                    trg_start = min(trg, trg_start)\n",
    "                    trg_end = max(trg, trg_end)\n",
    "                    \n",
    "            \n",
    "            if(trg_end - trg_start > cutoff - 1):\n",
    "                continue\n",
    "\n",
    "            phrase_pairs, A = extract(trg_start, trg_end, src_start, src_end, alignments, trg_aligned, len(trg_words))\n",
    "            \n",
    "            if (phrase_pairs):\n",
    "                extracted_phrases.extend(phrase_pairs)\n",
    "                for a in A:\n",
    "                    extracted_alignments.append(a);\n",
    "            \n",
    "    return extracted_phrases, extracted_alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49501 / 50000 (56s)                                                                                               \n",
      "Done!!!\n",
      "Total duration: 56s\n",
      "#unique en phrases: 1363321\n",
      "#unique de phrases: 1264713\n",
      "#unique (en,de) phrases: 2691953\n"
     ]
    }
   ],
   "source": [
    "def add_freq_dict(dictionary, item):\n",
    "    if item in dictionary:\n",
    "        dictionary[item] += 1\n",
    "    else:\n",
    "        dictionary[item] = 1\n",
    "\n",
    "        \n",
    "\n",
    "freq_pairs = dict()\n",
    "freq_src = dict()\n",
    "freq_trg = dict()\n",
    "    \n",
    "start_time = time.time()\n",
    "    \n",
    "for i in range(len(src_file)):\n",
    "    src_words = src_file[i].split()\n",
    "    trg_words = trg_file[i].split()        \n",
    "    alignments = [[int(a) for a in alignment.split('-')] for alignment in aligned_file[i].split()]\n",
    "    alignments = [(al[1], al[0]) for al in alignments]\n",
    "    \n",
    "    \n",
    "    phrase_pairs, extracted_alignments = extract_phrases(src_words, trg_words, alignments, 5)\n",
    "     \n",
    "    \n",
    "    for j, pair in enumerate(phrase_pairs):\n",
    "        \n",
    "        a = extracted_alignments[j]\n",
    "        \n",
    "        if pair in freq_pairs:\n",
    "            freq_pairs[pair][0] += 1;\n",
    "            freq_pairs[pair][1].add(tuple(a));\n",
    "        else:\n",
    "             freq_pairs[pair] = [1, set([tuple(a)])]\n",
    "        \n",
    "        \n",
    "        add_freq_dict(freq_trg, pair[0])\n",
    "        add_freq_dict(freq_src, pair[1])\n",
    "        \n",
    "    if (i % (len(src_file) / 100) == 0):\n",
    "        print(' \\r%d / %d (%ds)'%(i+1,len(src_file), time.time() - start_time), end = '')\n",
    "\n",
    "print()\n",
    "print('Done!!!')\n",
    "print('Total duration: %ds'%(time.time() - start_time))\n",
    "\n",
    "print(\"#unique en phrases: %d\"%(len(freq_trg)))\n",
    "print(\"#unique de phrases: %d\"%(len(freq_src)))\n",
    "print(\"#unique (en,de) phrases: %d\"%(len(freq_pairs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load/save dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save files\n",
    "# with open(\"data/freq_src_small\", 'wb') as file:\n",
    "#     pickle.dump(freq_src, file)\n",
    "\n",
    "# with open(\"data/freq_trg_small\", 'wb') as file:\n",
    "#     pickle.dump(freq_trg, file)\n",
    "\n",
    "# with open(\"data/freq_pairs_small\", 'wb') as file:\n",
    "#     pickle.dump(freq_pairs, file)\n",
    "\n",
    "with open(\"data/joined_freq_src\", 'rb') as file:\n",
    "    freq_src = pickle.load(file)\n",
    "\n",
    "with open(\"data/joined_freq_trg\", 'rb') as file:\n",
    "    freq_trg = pickle.load(file)\n",
    "\n",
    "with open(\"data/joined_freq_pairs\", 'rb') as file:\n",
    "    freq_pairs = pickle.load(file)\n",
    "        \n",
    "print(\"#en phrases: %d\"%(len(freq_src)))\n",
    "print(\"#de phrases: %d\"%(len(freq_trg)))\n",
    "print(\"#(en,de) phrases: %d\"%(len(freq_pairs)))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import operator\n",
    "# sorted_freq_src = sorted(freq_src.items(), key=operator.itemgetter(1), reverse = True)\n",
    "# sorted_freq_trg = sorted(freq_trg.items(), key=operator.itemgetter(1), reverse = True)\n",
    "# sorted_freq_pairs = sorted(freq_pairs.items(), key=operator.itemgetter(1), reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate p(e|f) and p(f|e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for trg_src_pair, value in freq_pairs.iteritems():\n",
    "    freq = value[0]\n",
    "    \n",
    "    p_src_trg = 1.0 * freq / freq_trg[trg_src_pair[0]]\n",
    "    p_trg_src = 1.0 * freq / freq_src[trg_src_pair[1]]\n",
    "    \n",
    "    freq_pairs[trg_src_pair] = [freq, value[1], p_src_trg, p_trg_src]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate lexical translation probabilities (KMO approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2691900 / 2691953 (99%) (216s)                                                                                              \n",
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "def KMO(src_words, trg_words, possible_alignments, w_trg_src):\n",
    "    \n",
    "    lex = -1\n",
    "    \n",
    "    for a in possible_alignments:\n",
    "    \n",
    "        mat = len(trg_words) * [None]\n",
    "\n",
    "        for (trg_pos, src_pos) in a:\n",
    "\n",
    "            src_word = src_words[src_pos]\n",
    "            trg_word = trg_words[trg_pos]\n",
    "\n",
    "            if mat[trg_pos] is None:\n",
    "                mat[trg_pos] = []\n",
    "\n",
    "            if (trg_word, src_word) in w_trg_src:\n",
    "                w = w_trg_src[(trg_word, src_word)] # w(e|f)\n",
    "\n",
    "                mat[trg_pos].append(w)\n",
    "\n",
    "            else:\n",
    "                mat[trg_pos].append(0)\n",
    "\n",
    "        for i in range(len(mat)):\n",
    "            if mat[i] is None:\n",
    "                mat[i] = 1\n",
    "            else:\n",
    "                mat[i] = numpy.mean(mat[i])\n",
    "\n",
    "    #     lex = numpy.sum(numpy.log(mat))\n",
    "        lex = max(lex, numpy.product(mat))\n",
    "    \n",
    "    return lex;\n",
    "\n",
    "\n",
    "c = 1\n",
    "start_time = time.time()\n",
    "\n",
    "for trg_src_pair, value in freq_pairs.iteritems():\n",
    "    \n",
    "    #calculate p(e|f)\n",
    "    trg_words = trg_src_pair[0].split()\n",
    "    src_words = trg_src_pair[1].split()\n",
    "    possible_alignments = value[1]\n",
    "    w_trg_src = {}\n",
    "    for a in possible_alignments:\n",
    "        for (trg_pos, src_pos) in a:\n",
    "            pair = (trg_words[trg_pos], src_words[src_pos])\n",
    "            if pair in freq_pairs:\n",
    "                w_trg_src[pair] = freq_pairs[pair][3]\n",
    "                \n",
    "                \n",
    "    lex_trg_src = KMO(src_words, trg_words, possible_alignments, w_trg_src);\n",
    "    \n",
    "    #cacluate p(f|e)\n",
    "    trg_words , src_words = src_words , trg_words\n",
    "\n",
    "    #reverse the alignments from (trg,src) to (src,trg)\n",
    "    possible_alignments2 = set()\n",
    "    for a in possible_alignments:\n",
    "        a2 = tuple([(al[1], al[0]) for al in a])\n",
    "        possible_alignments2.add(a2)\n",
    "        \n",
    "    w_src_trg = {}\n",
    "    for a in possible_alignments2:\n",
    "        for (trg_pos, src_pos) in a:\n",
    "            inv_pair = (src_words[src_pos], trg_words[trg_pos])\n",
    "            if inv_pair in freq_pairs:\n",
    "                w_src_trg[(inv_pair[1], inv_pair[0])] = freq_pairs[inv_pair][2]\n",
    "    \n",
    "    lex_src_trg = KMO(src_words, trg_words, possible_alignments2, w_src_trg)\n",
    "    \n",
    "    \n",
    "    \n",
    "    freq_pairs[trg_src_pair].append(lex_src_trg)\n",
    "    freq_pairs[trg_src_pair].append(lex_trg_src)\n",
    "        \n",
    "    if  c % (len(freq_pairs) / 100) == 0: \n",
    "        print(' \\r%d / %d (%d%%) (%ds)'%(c,len(freq_pairs), 100 * c / len(freq_pairs),time.time() - start_time), end = '')\n",
    "    c +=1\n",
    "        \n",
    "\n",
    "\n",
    "print('\\nDone!!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# with open(\"data/complete/freq_pair\", 'wb') as file:\n",
    "#     pickle.dump(freq_pairs,file)\n",
    "    \n",
    "# with open(\"data/complete/freq_src\", 'wb') as file:\n",
    "#     pickle.dump(freq_src,file)\n",
    "    \n",
    "# with open(\"data/complete/freq_trg\", 'wb') as file:\n",
    "#     pickle.dump(freq_trg,file)\n",
    "\n",
    "\n",
    "\n",
    "with open(\"data/complete/freq_pairs\", 'rb') as file:\n",
    "    freq_pairs = pickle.load(file)\n",
    "    \n",
    "with open(\"data/complete/freq_src\", 'rb') as file:\n",
    "    freq_src = pickle.load(file)\n",
    "    \n",
    "with open(\"data/complete/freq_trg\", 'rb') as file:\n",
    "    freq_trg = pickle.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import operator\n",
    "sorted_pairs = sorted(freq_pairs.keys(), key=operator.itemgetter(1), reverse = False)\n",
    "output_folder = 'C:/Users/Thanos/Desktop/outputs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the first file:   *f ||| e ||| freq(f) freq(e) freq(f; e)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2691900 / 2691953 (99%) (10s)                                       \n",
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "start_time = time.time();\n",
    "with open(output_folder + 'output1.txt', 'w') as the_file:\n",
    "\n",
    "    for pair in sorted_pairs: \n",
    "        f = pair[1]\n",
    "        e = pair[0]\n",
    " \n",
    "        freq_f = freq_src[f]\n",
    "        freq_e = freq_trg[e]\n",
    "        freq_fe = freq_pairs[pair][0]\n",
    "        \n",
    "        the_file.write('%s ||| %s ||| %d %d %d\\n' % (f,e,freq_f, freq_e, freq_fe))\n",
    "\n",
    "        if  c % (len(freq_pairs) / 100) == 0: \n",
    "            print(' \\r%d / %d (%d%%) (%ds)'%(c,len(sorted_pairs), 100 * c / len(sorted_pairs),time.time() - start_time), end = '')\n",
    "        c +=1\n",
    "\n",
    "print(\"\\nDone!!!\")\n",
    "# for i in range(400000, 400010):\n",
    "#     print(sorted_freq_pairs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the second file:  * f ||| e ||| p(f|e) p(e|f)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2691900 / 2691953 (99%) (8s)                               \n",
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "start_time = time.time();\n",
    "with open(output_folder + 'output2.txt', 'w') as the_file:\n",
    "\n",
    "    for pair in sorted_pairs: \n",
    "        f = pair[1]\n",
    "        e = pair[0]\n",
    " \n",
    "        p_f_e = freq_pairs[pair][2]\n",
    "        p_e_f = freq_pairs[pair][3]\n",
    "        \n",
    "        the_file.write('%s ||| %s ||| %f %f\\n' % (f, e, p_f_e, p_e_f))\n",
    "\n",
    "        if  c % (len(freq_pairs) / 100) == 0: \n",
    "            print(' \\r%d / %d (%d%%) (%ds)'%(c,len(sorted_pairs), 100 * c / len(sorted_pairs),time.time() - start_time), end = '')\n",
    "        c +=1\n",
    "\n",
    "print(\"\\nDone!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the third file:* f ||| e ||| p(f|e) p(e|f) l(f|e) l(e|f)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2691900 / 2691953 (99%) (11s)                                         \n",
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "start_time = time.time();\n",
    "with open(output_folder + 'output3.txt', 'w') as the_file:\n",
    "\n",
    "    for pair in sorted_pairs: \n",
    "        f = pair[1]\n",
    "        e = pair[0]\n",
    " \n",
    "        p_f_e = freq_pairs[pair][2]\n",
    "        p_e_f = freq_pairs[pair][3]\n",
    "        \n",
    "        l_f_e = freq_pairs[pair][4]\n",
    "        l_e_f = freq_pairs[pair][5]\n",
    "        \n",
    "        \n",
    "        the_file.write('%s ||| %s ||| %f %f %f %f\\n' % (f, e, p_f_e, p_e_f, l_f_e, l_e_f))\n",
    "\n",
    "        if  c % (len(freq_pairs) / 100) == 0: \n",
    "            print(' \\r%d / %d (%d%%) (%ds)'%(c,len(sorted_pairs), 100 * c / len(sorted_pairs),time.time() - start_time), end = '')\n",
    "        c +=1\n",
    "\n",
    "print(\"\\nDone!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the third file:* f ||| e ||| p(f|e) p(e|f) l(f|e) l(e|f) |||  freq(f) freq(e) freq(f; e)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2691900 / 2691953 (99%) (16s)                                              \n",
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "start_time = time.time();\n",
    "\n",
    "with open(output_folder + 'output_all.txt', 'w') as the_file:\n",
    "    for pair in sorted_pairs: \n",
    "        f = pair[1]\n",
    "        e = pair[0]\n",
    "        \n",
    "        freq_f = freq_src[f]\n",
    "        freq_e = freq_trg[e]\n",
    "        freq_fe = freq_pairs[pair][0]\n",
    " \n",
    "        p_f_e = freq_pairs[pair][2]\n",
    "        p_e_f = freq_pairs[pair][3]\n",
    "        \n",
    "        l_f_e = freq_pairs[pair][4]\n",
    "        l_e_f = freq_pairs[pair][5]\n",
    "        \n",
    "        \n",
    "        the_file.write('%s ||| %s ||| %f %f %f %f ||| %d %d %d \\n' % (f, e, p_f_e, p_e_f, l_f_e, l_e_f, freq_f, freq_e, freq_fe))\n",
    "\n",
    "        if  c % (len(freq_pairs) / 100) == 0: \n",
    "            print(' \\r%d / %d (%d%%) (%ds)'%(c,len(sorted_pairs), 100 * c / len(sorted_pairs),time.time() - start_time), end = '')\n",
    "        c +=1\n",
    "\n",
    "print(\"\\nDone!!!\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
