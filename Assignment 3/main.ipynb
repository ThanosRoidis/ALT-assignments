{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import time\n",
    "import pickle\n",
    "import operator\n",
    "from __future__ import print_function\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    \"\"\"Reads a file into a list of phrases. Each phrase in the file must be separated with a new line character '\\n' \n",
    "    Args:\n",
    "        filepath (str): the relevant filepath of the file\n",
    "    Returns:\n",
    "        phrases (list(str)): A list with all the phrases \n",
    "    \"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        phrases = f.readlines()\n",
    "    return phrases\n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Decoder:\n",
    "    def __init__(self, trg_lm_file, tm_file, rm_file):\n",
    "        \n",
    "        self.trg_LM = self.parse_lm_file(trg_lm_file)\n",
    "        self.TM = self.parse_tm_file(tm_file)\n",
    "        self.RM = self.parse_rm_file(rm_file)\n",
    "        \n",
    "        self.distortion_limit = 3\n",
    "        \n",
    "        \n",
    "    \n",
    "    def parse_lm_file(self, filepath):\n",
    "        lm_file = load_file(filepath)\n",
    "\n",
    "        LM = {}\n",
    "\n",
    "        for line in lm_file:\n",
    "            tokens = line.split()\n",
    "            if len(tokens) > 0:\n",
    "                if is_number(tokens[0]):\n",
    "\n",
    "                    p1 = float(tokens[0])\n",
    "\n",
    "                    s = tokens[1:]\n",
    "\n",
    "                    if is_number(s[-1]):\n",
    "                        p2 = float(s[-1])\n",
    "                        del s[-1]\n",
    "                        LM[\" \".join(s)] = [p1,p2]\n",
    "                    else:    \n",
    "                        LM[\" \".join(s)] = [p1]\n",
    "\n",
    "        return LM\n",
    "\n",
    "\n",
    "    def parse_tm_file(self, filepath):\n",
    "        tm_file = load_file(filepath)\n",
    "\n",
    "        TM = {}\n",
    "\n",
    "        for line in tm_file:\n",
    "            tokens = line.split(\"|||\")\n",
    "\n",
    "            f = tokens[0].strip()\n",
    "            e = tokens[1].strip()\n",
    "\n",
    "            tokens = tokens[2].split()\n",
    "\n",
    "\n",
    "            p_fe = float(tokens[0])\n",
    "            l_fe = float(tokens[1])\n",
    "            p_ef = float(tokens[2])\n",
    "            l_ef = float(tokens[3])\n",
    "            wp = float(tokens[4])\n",
    "\n",
    "            TM[(f,e)] = [p_fe, l_fe, p_ef, l_ef, wp]\n",
    "\n",
    "        return TM\n",
    "\n",
    "\n",
    "\n",
    "    def parse_rm_file(self, filepath):\n",
    "        re_file = load_file(filepath)\n",
    "\n",
    "        reorderings = {}\n",
    "\n",
    "        for line in re_file:\n",
    "            tokens = line.split(\"|||\")\n",
    "\n",
    "            f = tokens[0].strip()\n",
    "            e = tokens[1].strip()\n",
    "\n",
    "            tokens = tokens[2].split()\n",
    "\n",
    "            m_rl = float(tokens[0])\n",
    "            s_rl = float(tokens[1])\n",
    "            d_rl = float(tokens[2])\n",
    "\n",
    "            m_lr = float(tokens[3])\n",
    "            s_lr = float(tokens[4])\n",
    "            d_lr = float(tokens[5])\n",
    "\n",
    "            reorderings[(f,e)] = [m_rl, s_rl, d_rl, m_lr, s_lr, d_lr]\n",
    "\n",
    "        return reorderings\n",
    "    \n",
    "    \n",
    "    def parse_trace(self, trace_line):\n",
    "        \n",
    "        tokens = trace_line.split(\"|||\")\n",
    "        \n",
    "        trace = []\n",
    "        for token in tokens: \n",
    "            [src_positions, translation] = token.split(':',1) \n",
    "            \n",
    "            src_positions = [int(pos) for pos in src_positions.split(\"-\")]\n",
    "            \n",
    "            trace.append([src_positions[0], src_positions[1], translation.strip()])\n",
    "        \n",
    "        return trace\n",
    "    \n",
    "    \n",
    "    def translation_cost(self, src_phrase, trace):\n",
    "        \n",
    "        trace = self.parse_trace(trace)\n",
    "        src_words = src_phrase.split()\n",
    "        \n",
    "        \n",
    "        src_phrases = []\n",
    "        for p in trace:\n",
    "            src_phrase = \" \".join(src_words[p[0]:p[1] + 1])\n",
    "            src_phrases.append(src_phrase)\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        initial_State = State(null, -1, '')\n",
    "        \n",
    "        \n",
    "        cost = 0\n",
    "        translation = []\n",
    "        \n",
    "        trg_phrases = [p[2] for p in trace]\n",
    "        \n",
    "        \n",
    "        return translation, cost, zip(source_phrases, trg_phrases)\n",
    "    \n",
    "    \n",
    "    def explore(self, state, source_phrase, trace):\n",
    "        \n",
    "        next_states = []\n",
    "        \n",
    "        coverage_vector = state.coverage_vector\n",
    "        \n",
    "        untranslated_words = [pos for pos in range(len(coverage_vector)) if coverage_vector[pos] == 0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        return next_states\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "class State:\n",
    "        \n",
    "    id_counter = 0\n",
    "\n",
    "    def __init__(self, previous_state, source_phrase, translated_phrase):\n",
    "        \n",
    "        State.id_counter += 1\n",
    "        \n",
    "        self.id = State.id_counter\n",
    "        \n",
    "        self.previous_state = previous_state\n",
    "        \n",
    "        self.recombined_states = []\n",
    "        \n",
    "        self.history = []\n",
    "        \n",
    "        self.prob = []\n",
    "        \n",
    "        self.coverage_vector = []\n",
    "        \n",
    "        self.next_states = []\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_file = load_file('data/file.test.de')\n",
    "trg_file = load_file('data/file.test.en') \n",
    "traces =  load_file('data/testresults.trans.txt.trace')\n",
    "\n",
    "decoder = Decoder('data/file.en.lm', 'data/phrase-table', 'data/dm_fe_0.75')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('die', 'the'), ('arbeitsbedingungen', 'working conditions'), ('f\\xc3\\xbcr \\xc3\\xa4rzte in der ausbildung', 'for junior doctors'), ('gleichen', 'same'), ('einer', 'a'), ('horrorgeschichte', 'horrorgeschichte'), ('aus einem', 'from a'), ('dickens', 'dickens'), ('-', '-'), ('roman', 'a novel'), ('des', 'of'), ('neunzehnten', 'neunzehnten'), ('jahrhunderts .', 'century .')]\n",
      "\n",
      "\n",
      "[('es ist schon', 'it is'), ('recht', 'right'), ('merkw\\xc3\\xbcrdig , da\\xc3\\x9f wir', 'curious that we'), ('an der schwelle', 'entering the'), ('des 21', '21st'), ('. jahrhunderts', 'century'), ('noch immer', 'still'), ('f\\xc3\\xbcr', 'for'), ('vern\\xc3\\xbcnftige', 'reasonable'), ('regelungen in bezug auf', 'arrangements relating to'), ('den', 'the'), ('gesundheits - und', 'health and'), ('arbeitsschutz', 'arbeitsschutz'), ('k\\xc3\\xa4mpfen', 'struggles'), ('m\\xc3\\xbcssen .', '.')]\n",
      "\n",
      "\n",
      "[('ich appelliere an', 'i urge'), ('alle regierungen', 'all governments'), ('einschlie\\xc3\\x9flich der', 'including'), ('irischen', 'irish'), (',', ','), ('die', 'the'), ('zusatzbestimmungen', 'zusatzbestimmungen'), ('zur verl\\xc3\\xa4ngerung', 'the renewal'), ('des', 'of'), ('neunjahreszeitraums', 'neunjahreszeitraums'), ('zur umsetzung der', 'to implement the'), ('richtlinie nicht in', 'directive in'), ('anspruch', 'claim'), ('zu nehmen , und', 'and'), ('erinnere sie daran , da\\xc3\\x9f diese', 'these'), ('bestimmungen', 'provisions'), ('als', 'as'), ('ausnahmeregelung', 'derogation'), ('gedacht', 'intended'), ('sind', 'are'), (', die nur', 'only'), ('dann', 'then'), ('zur anwendung kommen soll', 'be applied'), (', wenn bereits', 'if'), ('alles', 'everything'), ('zur umsetzung der richtlinie', 'for implementing the directive'), ('getan wurde', 'was done'), ('.', '.')]\n",
      "\n",
      "\n",
      "[('herr', 'mr'), ('pr\\xc3\\xa4sident , der', 'president , the'), ('entwurf der richtlinie', 'draft directive'), ('\\xc3\\xbcber die arbeitszeitgestaltung', 'on the working time'), ('f\\xc3\\xbcr bestimmte', 'for certain'), ('besch\\xc3\\xa4ftigtenkategorien', 'besch\\xc3\\xa4ftigtenkategorien'), ('wie', 'as'), ('\\xc3\\xa4rzte in der ausbildung ,', 'junior doctors ,'), ('offshore - arbeitnehmer', 'offshore workers'), ('und', 'and'), ('sogenannte', 'called'), ('mobile', 'mobile'), ('arbeitnehmer', 'workers'), ('ist', 'is'), ('bezeichnend', 'indicative'), ('f\\xc3\\xbcr die', 'for the'), ('schwerf\\xc3\\xa4lligkeit und die', 'extraordinary weight and'), ('l\\xc3\\xa4cherlichkeit', 'people'), ('des sozialen europas', 'social europe'), ('.', '.')]\n",
      "\n",
      "\n",
      "[('in den', 'in the'), ('erw\\xc3\\xa4gungsgr\\xc3\\xbcnden des', 'of the recitals in the'), ('entwurfs', 'draft'), ('wird', 'will'), ('indes', 'now'), ('auf die', 'to the'), ('besondere', 'special'), ('bedeutung', 'importance'), ('dieses vorhabens', 'order'), ('hingewiesen ,', ','), ('da es sich um', 'as it is'), ('das erste', 'the first'), ('bedeutende', 'important'), ('dossier', 'dossier'), ('im sozialbereich', 'in the social'), ('handele', 'grounds'), (', das die', 'the'), ('gesundheit und', 'health and'), ('sicherheit von', 'safety of'), ('7', '7'), ('millionen', 'million'), ('arbeitnehmern', 'workers'), ('betrifft .', '.')]\n",
      "\n",
      "\n",
      "[('in frankreich', 'in france'), ('z.b.', 'for'), ('wurde die', 'the'), ('\\xc3\\xb6ffentlichkeit', 'public'), ('k\\xc3\\xbcrzlich durch', 'recently'), ('mehrere', 'several'), ('streiks', 'streiks'), ('von', 'of'), ('assistenz\\xc3\\xa4rzten', 'assistenz\\xc3\\xa4rzten'), ('auf die', 'on the'), ('unvertretbar', 'unacceptable'), ('lange', 'long'), ('arbeitzeit', 'arbeitzeit'), ('dieser', 'this'), ('besch\\xc3\\xa4ftigtenkategorie', 'besch\\xc3\\xa4ftigtenkategorie'), ('aufmerksam gemacht', 'attention'), (', die nicht', ', not'), ('nur f\\xc3\\xbcr die', 'only for the'), ('in der ausbildung', 'in training'), ('befindlichen', 'austrian'), ('\\xc3\\xa4rzte', 'doctors'), ('selbst', 'itself'), ('abtr\\xc3\\xa4glich ist', 'is'), (', sondern auch f\\xc3\\xbcr', ', but also for'), ('die qualit\\xc3\\xa4t der', 'the quality of'), ('\\xc3\\xa4rztlichen', '\\xc3\\xa4rztlichen'), ('versorgung der', 'feed the'), ('patienten', 'patients'), ('.', '.')]\n",
      "\n",
      "\n",
      "[('und die', 'and the'), ('gleiche', 'same'), ('frage', 'question'), ('stellt sich', 'is'), ('mehr oder weniger', 'more or less'), ('akut', 'akut'), ('auch', 'also'), ('f\\xc3\\xbcr die anderen', 'for the other'), ('arbeitnehmerkategorien', 'arbeitnehmerkategorien'), ('wie', 'as'), ('offshore -', 'offshore'), ('arbeitnehmer oder', 'workers or'), ('die besch\\xc3\\xa4ftigten', 'the employees'), ('im verkehrswesen', 'in transport'), ('.', '.')]\n",
      "\n",
      "\n",
      "[('dies h\\xc3\\xa4tte', 'it'), ('zu einer', 'to a'), ('raschen', 'rapid'), ('entscheidung', 'decision'), ('und einer', 'and a'), ('deutlichen', 'clear'), ('arbeitszeitreduzierung', 'arbeitszeitreduzierung'), ('m\\xc3\\xbcssen', 'must'), ('f\\xc3\\xbchren', 'lead'), ('.', '.')]\n",
      "\n",
      "\n",
      "[('mit den', 'with the'), ('entwurf', 'draft'), ('soll', 'is'), ('zwar die', 'the'), ('arbeitszeit', 'working'), ('verringert werden', 'be restricted'), (', jedoch nur', 'only'), ('schrittweise', 'gradual'), ('.', '.')]\n",
      "\n",
      "\n",
      "[('in den ersten drei', 'in the first three'), ('jahren sind', 'years are'), ('noch', 'still'), ('wochenarbeitszeiten', 'wochenarbeitszeiten'), ('von', 'of'), ('58', '58'), ('stunden', 'hours'), ('zul\\xc3\\xa4ssig .', '.')]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def translation_cost(src_phrase, trace):\n",
    "        \n",
    "        trace = decoder.parse_trace(trace)\n",
    "        src_words = src_phrase.split()\n",
    "        \n",
    "        \n",
    "        src_phrases = []\n",
    "        for p in trace:\n",
    "            src_phrase = \" \".join(src_words[p[0]:p[1] + 1])\n",
    "            src_phrases.append(src_phrase)\n",
    "            \n",
    "        \n",
    "        \n",
    "        cost = 0\n",
    "        translation = []\n",
    "        \n",
    "        trg_phrases = [p[2] for p in trace]\n",
    "        \n",
    "        \n",
    "        return translation, cost, zip(src_phrases, trg_phrases)\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    translation, cost, s = translation_cost(src_file[i], traces[i])\n",
    "    print(s)\n",
    "    print\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4]\n",
    "\n",
    "a[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.translation_cost = Decoder.translation_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 14.63 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "100000 loops, best of 3: 2.7 µs per loop\n",
      "1000000 loops, best of 3: 983 ns per loop\n",
      "The slowest run took 11.00 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 3: 1.36 µs per loop\n",
      "[1 3 5 8 9]\n",
      "[1, 3, 5, 8, 9]\n",
      "[1 3 5 8 9]\n"
     ]
    }
   ],
   "source": [
    "def test(l):\n",
    "    x = numpy.array(l)\n",
    "    return numpy.where(x == 0)[0]\n",
    "    \n",
    "    \n",
    "def test2(l):\n",
    "#     return [i for i in range(len(l)) if l[i] == 0]\n",
    "    return [i for i,v in enumerate(l) if v == 0]\n",
    "\n",
    "\n",
    "\n",
    "def test3(x):\n",
    "    return numpy.where(x == 0)[0]\n",
    "    \n",
    "l = [1,0,2,0,3,0,4,5,0,0,8]\n",
    "l_ar = numpy.array(l)\n",
    "\n",
    "%timeit test(l)\n",
    "%timeit test2(l)\n",
    "%timeit test3(l_ar)\n",
    "\n",
    "print(test(l))\n",
    "print(test2(l))\n",
    "print(test3(l_ar))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
