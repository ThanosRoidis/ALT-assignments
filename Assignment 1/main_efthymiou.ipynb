{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import time\n",
    "import pickle\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_file(filepath):\n",
    "    \n",
    "    with open(filepath, 'r') as f:\n",
    "        file = f.readlines()\n",
    "    return file\n",
    "\n",
    "src_file = load_file('data/file.de')\n",
    "trg_file = load_file('data/file.en')\n",
    "aligned_file = load_file('data/file.aligned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract(trg_start, trg_end, src_start, src_end, alignments, trg_aligned, trg_len):    \n",
    "\n",
    "    if trg_end < 0 :\n",
    "        return [], []\n",
    "    \n",
    "    A = []\n",
    "    \n",
    "    a = []\n",
    "    \n",
    "    for trg_word, src_word  in alignments:\n",
    "        if trg_start <= trg_word <= trg_end:\n",
    "            \n",
    "            if (src_word < src_start or src_word > src_end):  \n",
    "                return [], []\n",
    "            else:\n",
    "                \n",
    "                a.append( (trg_word - trg_start, src_word - src_start) )\n",
    "\n",
    "    E = []\n",
    "    trg_s = trg_start\n",
    "    \n",
    "    while True:\n",
    "        trg_e = trg_end\n",
    "        while True:\n",
    "            #E.append( (tuple(trg_words[trg_s:trg_e+1]) , tuple(src_words[src_start:src_end+1])) )\n",
    "            E.append( (\" \".join(trg_words[trg_s:trg_e+1]) , \" \".join(src_words[src_start:src_end+1]) ))\n",
    "            \n",
    "            A.append(a)\n",
    "             \n",
    "            trg_e += 1\n",
    "            \n",
    "            if trg_e in trg_aligned or trg_e == len(trg_words):\n",
    "                break \n",
    "\n",
    "        trg_s -= 1\n",
    "        \n",
    "        if trg_s in trg_aligned or trg_s < 0:\n",
    "            break\n",
    "       \n",
    "        a = [(i[0]+1,i[1]) for i in a]\n",
    "        \n",
    "    return E, A\n",
    "\n",
    "\n",
    "def extract_phrases(src_words, trg_words, alignments, cutoff):\n",
    "    \n",
    "    \n",
    "    if cutoff == -1:\n",
    "        cutoff = len(src_words)\n",
    "        \n",
    "        \n",
    "    trg_aligned = set()\n",
    "    for (trg,_) in alignments:\n",
    "        trg_aligned.add(trg)\n",
    "    \n",
    "    \n",
    "    extracted_phrases = []\n",
    "    extracted_alignments = []\n",
    "    for src_start in range(len(src_words)):\n",
    "        for src_end in range(src_start, min(src_start + cutoff, len(src_words))):\n",
    "\n",
    "            trg_start = len(trg_words) - 1\n",
    "            trg_end = - 1\n",
    "            for  (trg,src) in alignments: \n",
    "                if src_start <= src <= src_end:\n",
    "                    trg_start = min(trg, trg_start)\n",
    "                    trg_end = max(trg, trg_end)\n",
    "                    \n",
    "            \n",
    "            if(trg_end - trg_start > cutoff - 1):\n",
    "                continue\n",
    "\n",
    "            phrase_pairs, A = extract(trg_start, trg_end, src_start, src_end, alignments, trg_aligned, len(trg_words))\n",
    "            \n",
    "            if (phrase_pairs):\n",
    "                extracted_phrases.extend(phrase_pairs)\n",
    "                for a in A:\n",
    "                    extracted_alignments.append(a);\n",
    "            \n",
    "    return extracted_phrases, extracted_alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49501 / 50000 (56s)                                                                                               \n",
      "Done!!!\n",
      "Total duration: 56s\n",
      "#unique en phrases: 1363321\n",
      "#unique de phrases: 1264713\n",
      "#unique (en,de) phrases: 2691953\n"
     ]
    }
   ],
   "source": [
    "def add_freq_dict(dictionary, item):\n",
    "    if item in dictionary:\n",
    "        dictionary[item] += 1\n",
    "    else:\n",
    "        dictionary[item] = 1\n",
    "\n",
    "        \n",
    "\n",
    "freq_pairs = dict()\n",
    "freq_src = dict()\n",
    "freq_trg = dict()\n",
    "    \n",
    "start_time = time.time()\n",
    "    \n",
    "for i in range(len(src_file)):\n",
    "    src_words = src_file[i].split()\n",
    "    trg_words = trg_file[i].split()        \n",
    "    alignments = [[int(a) for a in alignment.split('-')] for alignment in aligned_file[i].split()]\n",
    "    alignments = [(al[1], al[0]) for al in alignments]\n",
    "    \n",
    "    \n",
    "    phrase_pairs, extracted_alignments = extract_phrases(src_words, trg_words, alignments, 5)\n",
    "     \n",
    "    \n",
    "    for j, pair in enumerate(phrase_pairs):\n",
    "        \n",
    "        a = extracted_alignments[j]\n",
    "        \n",
    "        if pair in freq_pairs:\n",
    "            freq_pairs[pair][0] += 1;\n",
    "            freq_pairs[pair][1].add(tuple(a));\n",
    "        else:\n",
    "             freq_pairs[pair] = [1, set([tuple(a)])]\n",
    "        \n",
    "        \n",
    "        add_freq_dict(freq_trg, pair[0])\n",
    "        add_freq_dict(freq_src, pair[1])\n",
    "        \n",
    "    if (i % (len(src_file) / 100) == 0):\n",
    "        print(' \\r%d / %d (%ds)'%(i+1,len(src_file), time.time() - start_time), end = '')\n",
    "\n",
    "print()\n",
    "print('Done!!!')\n",
    "print('Total duration: %ds'%(time.time() - start_time))\n",
    "\n",
    "print(\"#unique en phrases: %d\"%(len(freq_trg)))\n",
    "print(\"#unique de phrases: %d\"%(len(freq_src)))\n",
    "print(\"#unique (en,de) phrases: %d\"%(len(freq_pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mr president', 'herr pr\\xc3\\xa4sident') [1389, set([((0, 0), (1, 0), (1, 1)), ((0, 0), (1, 1))])]\n"
     ]
    }
   ],
   "source": [
    "for key in freq_pairs.keys()[0:100]:\n",
    "    if(len(freq_pairs[key][1]) > 1):\n",
    "        print(key, freq_pairs[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load/save dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save files\n",
    "# with open(\"data/freq_src_small\", 'wb') as file:\n",
    "#     pickle.dump(freq_src, file)\n",
    "\n",
    "# with open(\"data/freq_trg_small\", 'wb') as file:\n",
    "#     pickle.dump(freq_trg, file)\n",
    "\n",
    "# with open(\"data/freq_pairs_small\", 'wb') as file:\n",
    "#     pickle.dump(freq_pairs, file)\n",
    "\n",
    "with open(\"data/joined_freq_src\", 'rb') as file:\n",
    "    freq_src = pickle.load(file)\n",
    "\n",
    "with open(\"data/joined_freq_trg\", 'rb') as file:\n",
    "    freq_trg = pickle.load(file)\n",
    "\n",
    "with open(\"data/joined_freq_pairs\", 'rb') as file:\n",
    "    freq_pairs = pickle.load(file)\n",
    "        \n",
    "print(\"#en phrases: %d\"%(len(freq_src)))\n",
    "print(\"#de phrases: %d\"%(len(freq_trg)))\n",
    "print(\"#(en,de) phrases: %d\"%(len(freq_pairs)))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import operator\n",
    "# sorted_freq_src = sorted(freq_src.items(), key=operator.itemgetter(1), reverse = True)\n",
    "# sorted_freq_trg = sorted(freq_trg.items(), key=operator.itemgetter(1), reverse = True)\n",
    "# sorted_freq_pairs = sorted(freq_pairs.items(), key=operator.itemgetter(1), reverse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate p(e|f) and p(f|e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for trg_src_pair, value in freq_pairs.iteritems():\n",
    "    freq = value[0]\n",
    "    \n",
    "    p_src_trg = 1.0 * freq / freq_trg[trg_src_pair[0]]\n",
    "    p_trg_src = 1.0 * freq / freq_src[trg_src_pair[1]]\n",
    "    \n",
    "    freq_pairs[trg_src_pair] = [freq, value[1], p_src_trg, p_trg_src]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('do we believe', 'wir') [1, set([((1, 0),)]), 0.2, 6.532105297537396e-05]\n",
      "(', mr langen ,', ', langen ,') [1, set([((0, 0), (2, 1), (3, 2))]), 0.2, 1.0]\n",
      "('parliament and in the council', 'parlament als auch im rat') [1, set([((0, 0), (1, 1), (1, 2), (2, 3), (3, 3), (4, 4))]), 1.0, 0.5]\n",
      "('to raise', 'zu einem thema zu machen') [1, set([((0, 3), (1, 2))]), 0.019230769230769232, 1.0]\n",
      "('the various stages of close', 'auf die verschiedenen etappen verlangen') [1, set([((0, 1), (1, 2), (2, 3))]), 0.2, 0.3333333333333333]\n",
      "('mr kouchner', 'da\\xc3\\x9f herrn kouchner') [1, set([((0, 1), (1, 0), (1, 2))]), 0.041666666666666664, 1.0]\n",
      "('you know very well', 'bekanntlich ergibt sich') [1, set([((0, 0), (1, 0), (2, 1), (3, 0))]), 0.25, 1.0]\n",
      "('article 87 ( 2 )', 'artikel 87 absatz 2') [2, set([((0, 0), (1, 1), (2, 2), (3, 3), (4, 2))]), 1.0, 0.6666666666666666]\n",
      "('900', 'mittelzuweisungen ( 900') [1, set([((0, 0), (0, 1), (0, 2))]), 0.3333333333333333, 1.0]\n",
      "('a newspaper article which appeared', 'in') [1, set([((2, 0),)]), 1.0, 4.4917576247585683e-05]\n"
     ]
    }
   ],
   "source": [
    "for key in freq_pairs.keys()[0:10]:\n",
    "    print(key, freq_pairs[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2691900 / 2691953 (99%) (109s)\\Done!!                                                                                       \n"
     ]
    }
   ],
   "source": [
    "# c = 1\n",
    "# start_time = time.time()\n",
    "\n",
    "# for trg_src_pair, value in freq_pairs.iteritems():\n",
    "#     pair_freq = value[0]\n",
    "#     trg_words = trg_src_pair[0].split()\n",
    "#     src_words = trg_src_pair[1].split()\n",
    "    \n",
    "#     possible_alignments = value[1]\n",
    "    \n",
    "#     lex = -1;\n",
    "    \n",
    "#     for a in possible_alignments:\n",
    "    \n",
    "#         mat = len(trg_words) * [None]\n",
    "\n",
    "#         for (trg_pos, src_pos) in a:\n",
    "\n",
    "#             src_word = src_words[src_pos]\n",
    "#             trg_word = trg_words[trg_pos]\n",
    "\n",
    "#             if mat[trg_pos] is None:\n",
    "#                 mat[trg_pos] = []\n",
    "\n",
    "#             if (trg_word, src_word) in freq_pairs:\n",
    "#                 w = freq_pairs[(trg_word, src_word)][3] # w(e|f)\n",
    "\n",
    "#                 mat[trg_pos].append(w)\n",
    "\n",
    "#             else:\n",
    "#                 mat[trg_pos].append(0)\n",
    "\n",
    "#         for i in range(len(mat)):\n",
    "#             if mat[i] is None:\n",
    "#                 mat[i] = 1\n",
    "#             else:\n",
    "#                 mat[i] = numpy.mean(mat[i])\n",
    "\n",
    "#     #     lex = numpy.sum(numpy.log(mat))\n",
    "#         lex = max(lex, numpy.product(mat))\n",
    "    \n",
    "#     freq_pairs[trg_src_pair].append(lex)\n",
    "        \n",
    "#     if  c % (len(freq_pairs) / 100) == 0: \n",
    "#         print(' \\r%d / %d (%d%%) (%ds)'%(c,len(freq_pairs), 100 * c / len(freq_pairs),time.time() - start_time), end = '')\n",
    "#     c +=1\n",
    "        \n",
    "# print('\\nDone!!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('do we believe', 'wir') [1, set([((1, 0),)]), 0.2, 6.532105297537396e-05, 0.67777124567248026]\n",
      "(', mr langen ,', ', langen ,') [1, set([((0, 0), (2, 1), (3, 2))]), 0.2, 1.0, 0.055294363579737778]\n",
      "('parliament and in the council', 'parlament als auch im rat') [1, set([((0, 0), (1, 1), (1, 2), (2, 3), (3, 3), (4, 4))]), 1.0, 0.5, 0.00032486683238314493]\n",
      "('to raise', 'zu einem thema zu machen') [1, set([((0, 3), (1, 2))]), 0.019230769230769232, 1.0, 0.0019659398530738762]\n",
      "('the various stages of close', 'auf die verschiedenen etappen verlangen') [1, set([((0, 1), (1, 2), (2, 3))]), 0.2, 0.3333333333333333, 0.066741572848568728]\n",
      "('mr kouchner', 'da\\xc3\\x9f herrn kouchner') [1, set([((0, 1), (1, 0), (1, 2))]), 0.041666666666666664, 1.0, 0.19401330376940132]\n",
      "('you know very well', 'bekanntlich ergibt sich') [1, set([((0, 0), (1, 0), (2, 1), (3, 0))]), 0.25, 1.0, 0.0]\n",
      "('article 87 ( 2 )', 'artikel 87 absatz 2') [2, set([((0, 0), (1, 1), (2, 2), (3, 3), (4, 2))]), 1.0, 0.6666666666666666, 0.0]\n",
      "('900', 'mittelzuweisungen ( 900') [1, set([((0, 0), (0, 1), (0, 2))]), 0.3333333333333333, 1.0, 0.33333333333333331]\n",
      "('a newspaper article which appeared', 'in') [1, set([((2, 0),)]), 1.0, 4.4917576247585683e-05, 4.4917576247585683e-05]\n"
     ]
    }
   ],
   "source": [
    "for key in freq_pairs.keys()[0:10]:\n",
    "    print(key, freq_pairs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2691900 / 2691953 (99%) (216s)                                                                                              \n",
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "def KMO(src_words, trg_words, possible_alignments, w_trg_src):\n",
    "    \n",
    "    lex = -1\n",
    "    \n",
    "    for a in possible_alignments:\n",
    "    \n",
    "        mat = len(trg_words) * [None]\n",
    "\n",
    "        for (trg_pos, src_pos) in a:\n",
    "\n",
    "            src_word = src_words[src_pos]\n",
    "            trg_word = trg_words[trg_pos]\n",
    "\n",
    "            if mat[trg_pos] is None:\n",
    "                mat[trg_pos] = []\n",
    "\n",
    "            if (trg_word, src_word) in w_trg_src:\n",
    "                w = w_trg_src[(trg_word, src_word)] # w(e|f)\n",
    "\n",
    "                mat[trg_pos].append(w)\n",
    "\n",
    "            else:\n",
    "                mat[trg_pos].append(0)\n",
    "\n",
    "        for i in range(len(mat)):\n",
    "            if mat[i] is None:\n",
    "                mat[i] = 1\n",
    "            else:\n",
    "                mat[i] = numpy.mean(mat[i])\n",
    "\n",
    "    #     lex = numpy.sum(numpy.log(mat))\n",
    "        lex = max(lex, numpy.product(mat))\n",
    "    \n",
    "    return lex;\n",
    "\n",
    "\n",
    "c = 1\n",
    "start_time = time.time()\n",
    "\n",
    "for trg_src_pair, value in freq_pairs.iteritems():\n",
    "    \n",
    "    #calculate p(e|f)\n",
    "    trg_words = trg_src_pair[0].split()\n",
    "    src_words = trg_src_pair[1].split()\n",
    "    possible_alignments = value[1]\n",
    "    w_trg_src = {}\n",
    "    for a in possible_alignments:\n",
    "        for (trg_pos, src_pos) in a:\n",
    "            pair = (trg_words[trg_pos], src_words[src_pos])\n",
    "            if pair in freq_pairs:\n",
    "                w_trg_src[pair] = freq_pairs[pair][3]\n",
    "                \n",
    "                \n",
    "    lex_trg_src = KMO(src_words, trg_words, possible_alignments, w_trg_src);\n",
    "    \n",
    "    #cacluate p(f|e)\n",
    "    trg_words , src_words = src_words , trg_words\n",
    "\n",
    "    #reverse the alignments from (trg,src) to (src,trg)\n",
    "    possible_alignments2 = set()\n",
    "    for a in possible_alignments:\n",
    "        a2 = tuple([(al[1], al[0]) for al in a])\n",
    "        possible_alignments2.add(a2)\n",
    "        \n",
    "    w_src_trg = {}\n",
    "    for a in possible_alignments2:\n",
    "        for (trg_pos, src_pos) in a:\n",
    "            inv_pair = (src_words[src_pos], trg_words[trg_pos])\n",
    "            if inv_pair in freq_pairs:\n",
    "                w_src_trg[(inv_pair[1], inv_pair[0])] = freq_pairs[inv_pair][2]\n",
    "    \n",
    "    lex_src_trg = KMO(src_words, trg_words, possible_alignments2, w_src_trg)\n",
    "    \n",
    "    \n",
    "    \n",
    "    freq_pairs[trg_src_pair].append(lex_src_trg)\n",
    "    freq_pairs[trg_src_pair].append(lex_trg_src)\n",
    "        \n",
    "    if  c % (len(freq_pairs) / 100) == 0: \n",
    "        print(' \\r%d / %d (%d%%) (%ds)'%(c,len(freq_pairs), 100 * c / len(freq_pairs),time.time() - start_time), end = '')\n",
    "    c +=1\n",
    "        \n",
    "\n",
    "\n",
    "print('\\nDone!!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('do we believe', 'wir') [1, set([((1, 0),)]), 0.2, 6.532105297537396e-05, 0.60809939635468557, 0.67777124567248026]\n",
      "(', mr langen ,', ', langen ,') [1, set([((0, 0), (2, 1), (3, 2))]), 0.2, 1.0, 0.27708848798290681, 0.055294363579737778]\n",
      "('parliament and in the council', 'parlament als auch im rat') [1, set([((0, 0), (1, 1), (1, 2), (2, 3), (3, 3), (4, 4))]), 1.0, 0.5, 9.0464324715546004e-08, 0.00032486683238314493]\n",
      "('to raise', 'zu einem thema zu machen') [1, set([((0, 3), (1, 2))]), 0.019230769230769232, 1.0, 0.0066933871793610801, 0.0019659398530738762]\n",
      "('the various stages of close', 'auf die verschiedenen etappen verlangen') [1, set([((0, 1), (1, 2), (2, 3))]), 0.2, 0.3333333333333333, 0.011257902576663648, 0.066741572848568728]\n",
      "('mr kouchner', 'da\\xc3\\x9f herrn kouchner') [1, set([((0, 1), (1, 0), (1, 2))]), 0.041666666666666664, 1.0, 0.0, 0.19401330376940132]\n",
      "('you know very well', 'bekanntlich ergibt sich') [1, set([((0, 0), (1, 0), (2, 1), (3, 0))]), 0.25, 1.0, 6.0367641541773932e-07, 0.0]\n",
      "('article 87 ( 2 )', 'artikel 87 absatz 2') [2, set([((0, 0), (1, 1), (2, 2), (3, 3), (4, 2))]), 1.0, 0.6666666666666666, 0.0014648244545751737, 0.0]\n",
      "('900', 'mittelzuweisungen ( 900') [1, set([((0, 0), (0, 1), (0, 2))]), 0.3333333333333333, 1.0, 0.0, 0.33333333333333331]\n",
      "('a newspaper article which appeared', 'in') [1, set([((2, 0),)]), 1.0, 4.4917576247585683e-05, 0.0016920473773265651, 4.4917576247585683e-05]\n"
     ]
    }
   ],
   "source": [
    "for key in freq_pairs.keys()[0:10]:\n",
    "    print(key, freq_pairs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10376,\n",
       " {((0, 0),)},\n",
       " 0.6080993963546856,\n",
       " 0.6777712456724803,\n",
       " 0.60809939635468557,\n",
       " 0.67777124567248026]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_pairs[('we', 'wir')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# with open(\"data/complete/freq_pair\", 'wb') as file:\n",
    "#     pickle.dump(freq_pairs,file)\n",
    "    \n",
    "# with open(\"data/complete/freq_src\", 'wb') as file:\n",
    "#     pickle.dump(freq_src,file)\n",
    "    \n",
    "# with open(\"data/complete/freq_trg\", 'wb') as file:\n",
    "#     pickle.dump(freq_trg,file)\n",
    "\n",
    "\n",
    "\n",
    "with open(\"data/complete/freq_pairs\", 'rb') as file:\n",
    "    freq_pairs = pickle.load(file)\n",
    "    \n",
    "with open(\"data/complete/freq_src\", 'rb') as file:\n",
    "    freq_src = pickle.load(file)\n",
    "    \n",
    "with open(\"data/complete/freq_trg\", 'rb') as file:\n",
    "    freq_trg = pickle.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " {((0, 0),)},\n",
       " 0.0006038647342995169,\n",
       " 0.009523809523809525,\n",
       " 0.00060386473429951688,\n",
       " 0.0095238095238095247]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_pairs[('you','bekanntlich')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " {((0, 0),)},\n",
       " 0.0024875621890547263,\n",
       " 0.009523809523809525,\n",
       " 0.0024875621890547263,\n",
       " 0.0095238095238095247]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_pairs[('know','bekanntlich')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('well', 'bekanntlich')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a131f560d7c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfreq_pairs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'well'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'bekanntlich'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: ('well', 'bekanntlich')"
     ]
    }
   ],
   "source": [
    "freq_pairs[('well','bekanntlich')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " {((0, 0),)},\n",
       " 0.0005858230814294083,\n",
       " 0.03571428571428571,\n",
       " 0.00058582308142940832,\n",
       " 0.035714285714285712]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_pairs[('very','ergibt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.036764154177393e-07"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " 0.0005858230814294083 * ( 0.0006038647342995169 +  0.0024875621890547263) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.036764154177393e-07"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6.0367641541773932e-07"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
