{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import time\n",
    "import pickle\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_file(filepath):\n",
    "    \n",
    "    with open(filepath, 'r') as f:\n",
    "        file = f.readlines()\n",
    "    return file\n",
    "\n",
    "src_file = load_file('data/file.en')\n",
    "trg_file = load_file('data/file.de')\n",
    "aligned_file = load_file('data/file.aligned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(trg_start, trg_end, src_start, src_end, alignments, trg_aligned, trg_len):    \n",
    "  \n",
    "\n",
    "    if trg_end < 0 :\n",
    "        return [], []\n",
    "    \n",
    "    a = []\n",
    "    \n",
    "    for trg_word, src_word  in alignments:\n",
    "        if trg_start <= trg_word <= trg_end:\n",
    "            \n",
    "            if (src_word < src_start or src_word > src_end):  \n",
    "                return [], []\n",
    "            else:\n",
    "                a.append( (trg_word - trg_start, src_word - src_start) )\n",
    "            \n",
    "        \n",
    "    E = []\n",
    "    trg_s = trg_start\n",
    "    \n",
    "    while True:\n",
    "        trg_e = trg_end\n",
    "        while True:\n",
    "            #E.append( (tuple(trg_words[trg_s:trg_e+1]) , tuple(src_words[src_start:src_end+1])) )\n",
    "            E.append( (\" \".join(trg_words[trg_s:trg_e+1]) , \" \".join(src_words[src_start:src_end+1]) ))\n",
    "            \n",
    "            trg_e += 1\n",
    "            \n",
    "            if trg_e in trg_aligned or trg_e == len(trg_words):\n",
    "                break \n",
    "    \n",
    "        trg_s -= 1\n",
    "        \n",
    "        if trg_s in trg_aligned or trg_s < 0:\n",
    "            break\n",
    "    return E, a\n",
    "\n",
    "\n",
    "def extract_phrases(src_words, trg_words, alignments, cutoff):\n",
    "    \n",
    "    \n",
    "    if cutoff == -1:\n",
    "        cutoff = len(src_words)\n",
    "        \n",
    "        \n",
    "    trg_aligned = set()\n",
    "    for (trg,_) in alignments:\n",
    "        trg_aligned.add(trg)\n",
    "    \n",
    "    \n",
    "    extracted_phrases = []\n",
    "    extracted_alignments = []\n",
    "    for src_start in range(len(src_words)):\n",
    "        for src_end in range(src_start, min(src_start + cutoff, len(src_words))):\n",
    "\n",
    "            trg_start = len(trg_words) - 1\n",
    "            trg_end = - 1\n",
    "            for  (trg,src) in alignments: \n",
    "                if src_start <= src <= src_end:\n",
    "                    trg_start = min(trg, trg_start)\n",
    "                    trg_end = max(trg, trg_end)\n",
    "                    \n",
    "            \n",
    "            if(trg_end - trg_start > cutoff - 1):\n",
    "                continue\n",
    "\n",
    "            phrase_pairs, a = extract(trg_start, trg_end, src_start, src_end, alignments, trg_aligned, len(trg_words))\n",
    "            \n",
    "            if (phrase_pairs):\n",
    "                extracted_phrases.extend(phrase_pairs)\n",
    "                for i in phrase_pairs:\n",
    "                    extracted_alignments.append(a);\n",
    "            \n",
    "    return extracted_phrases, extracted_alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# src_words = \"michael assumes that he will stay in the house\".split()\n",
    "# trg_words = \"michael geht davon aus , dass er im haus bleibt\".split()\n",
    "# alignments = [(0,0), (1,1), (2,1), (3,1), (5,2), (6,3), (9,4), (9,5), (7,6), (7,7), (8,8)]\n",
    " \n",
    "# BP = extract_phrases(src_words, trg_words, alignments)\n",
    "    \n",
    "# freq_pairs = dict()\n",
    "# freq_src = dict()\n",
    "# freq_trg = dict()\n",
    "    \n",
    "# for pair in BP:\n",
    "#     add_freq_dict(freq_pairs,pair)\n",
    "#     add_freq_dict(freq_trg, pair[0])\n",
    "#     add_freq_dict(freq_src, pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 / 50000 (75s)                                                                                                                                                                                                                                                                                                                                                                \n",
      "Done!!!\n",
      "Total duration: 75s\n",
      "#en phrases: 1189230\n",
      "#de phrases: 1386442\n",
      "#(en,de) phrases: 2624229\n"
     ]
    }
   ],
   "source": [
    "def add_freq_dict(dictionary, item):\n",
    "    if item in dictionary:\n",
    "        dictionary[item] += 1\n",
    "    else:\n",
    "        dictionary[item] = 1\n",
    "\n",
    "        \n",
    "\n",
    "freq_pairs = dict()\n",
    "freq_src = dict()\n",
    "freq_trg = dict()\n",
    "    \n",
    "start_time = time.time()\n",
    "    \n",
    "for i in range(len(src_file)):\n",
    "    src_words = src_file[i].split()\n",
    "    trg_words = trg_file[i].split()        \n",
    "    alignments = [[int(a) for a in alignment.split('-')] for alignment in aligned_file[i].split()]\n",
    "    \n",
    "    phrase_pairs, extracted_alignments = extract_phrases(src_words, trg_words, alignments, 5)\n",
    "    \n",
    "#     for k in range(len(BP)):\n",
    "#         print(BP[k], a[k])\n",
    "#     break;\n",
    "    \n",
    "    for j, pair in enumerate(phrase_pairs):\n",
    "        \n",
    "        a = extracted_alignments[j]\n",
    "        \n",
    "        if pair in freq_pairs:\n",
    "            freq_pairs[pair][0] += 1;\n",
    "        else:\n",
    "             freq_pairs[pair] = [1, a]\n",
    "        \n",
    "        \n",
    "        add_freq_dict(freq_trg, pair[0])\n",
    "        add_freq_dict(freq_src, pair[1])\n",
    "        \n",
    "    print(' \\r%d / %d (%ds)'%(i+1,len(src_file), time.time() - start_time), end = '')\n",
    "\n",
    "print()\n",
    "print('Done!!!')\n",
    "print('Total duration: %ds'%(time.time() - start_time))\n",
    "\n",
    "print(\"#en phrases: %d\"%(len(freq_src)))\n",
    "print(\"#de phrases: %d\"%(len(freq_trg)))\n",
    "print(\"#(en,de) phrases: %d\"%(len(freq_pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phrase_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extracted_alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('darauf , wie die tiere', 'to the transfer of animals') [1, [(0, 0), (1, 0), (3, 1), (2, 2), (4, 4)]]\n",
      "('geht', 'is needed') [1, [(0, 0)]]\n",
      "('es ist nicht richtig , wenn hier', 'you are wrong to') [1, [(0, 0), (1, 1), (2, 2), (3, 2), (4, 3)]]\n",
      "('auf die kommission an', \"in the commission 's court\") [1, [(0, 0), (1, 1), (2, 2), (2, 3), (3, 3), (3, 4)]]\n",
      "('der ausgangspunkt', 'the point') [1, [(0, 0), (1, 1)]]\n",
      "('die erarbeitung', 'communication') [1, [(0, 0)]]\n",
      "('widersinnig und nicht', 'nonsensical and contrary to') [1, [(0, 0), (1, 1), (0, 2), (2, 2)]]\n",
      "('informieren und dort eine kritik anzubringen', 'and then levy criticism') [1, [(0, 0), (1, 1), (2, 2), (4, 2), (3, 3)]]\n",
      "('entwicklungspolitik steht im zusammenhang', 'development policies relates') [1, [(0, 0), (0, 1), (1, 2), (2, 2), (3, 2)]]\n",
      "('f\\xc3\\xbcr die umsetzungsmodalit\\xc3\\xa4ten der', 'for the implementation methods for') [1, [(0, 0), (1, 1), (2, 2), (2, 3), (2, 4), (3, 4)]]\n"
     ]
    }
   ],
   "source": [
    "for key in freq_pairs.keys()[10:20]:\n",
    "    print(key, freq_pairs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f√ºr\n"
     ]
    }
   ],
   "source": [
    "print('f\\xc3\\xbcr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# freq_pairs = dict()\n",
    "# freq_src = dict()\n",
    "# freq_trg = dict()\n",
    "    \n",
    "# start_time = time.time()\n",
    "    \n",
    "# for i in range(len(src_file)):\n",
    "#     src_words = src_file[i].split()\n",
    "#     trg_words = trg_file[i].split()        \n",
    "#     alignments = [[int(a) for a in alignment.split('-')] for alignment in aligned_file[i].split()]\n",
    "    \n",
    "#     BP = extract_phrases(src_words, trg_words, alignments)\n",
    "    \n",
    "#     for pair in BP:\n",
    "#         add_freq_dict(freq_pairs,pair)\n",
    "#         add_freq_dict(freq_trg, pair[0])\n",
    "#         add_freq_dict(freq_src, pair[1])\n",
    "        \n",
    "#     print(' \\r%d / %d (%ds)'%(i+1,len(src_file), time.time() - start_time), end = '')\n",
    "\n",
    "# print()\n",
    "# print('Done!!!')\n",
    "# print('Total duration: %ds'%(time.time() - start_time))\n",
    "\n",
    "# print(\"#en phrases: %d\"%(len(freq_src)))\n",
    "# print(\"#de phrases: %d\"%(len(freq_trg)))\n",
    "# print(\"#(en,de) phrases: %d\"%(len(freq_pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save files\n",
    "# with open(\"data/freq_src_small\", 'wb') as file:\n",
    "#     pickle.dump(freq_src, file)\n",
    "\n",
    "# with open(\"data/freq_trg_small\", 'wb') as file:\n",
    "#     pickle.dump(freq_trg, file)\n",
    "\n",
    "# with open(\"data/freq_pairs_small\", 'wb') as file:\n",
    "#     pickle.dump(freq_pairs, file)\n",
    "\n",
    "with open(\"data/joined_freq_src\", 'rb') as file:\n",
    "    freq_src = pickle.load(file)\n",
    "\n",
    "with open(\"data/joined_freq_trg\", 'rb') as file:\n",
    "    freq_trg = pickle.load(file)\n",
    "\n",
    "with open(\"data/joined_freq_pairs\", 'rb') as file:\n",
    "    freq_pairs = pickle.load(file)\n",
    "        \n",
    "print(\"#en phrases: %d\"%(len(freq_src)))\n",
    "print(\"#de phrases: %d\"%(len(freq_trg)))\n",
    "print(\"#(en,de) phrases: %d\"%(len(freq_pairs)))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import operator\n",
    "# sorted_freq_src = sorted(freq_src.items(), key=operator.itemgetter(1), reverse = True)\n",
    "# sorted_freq_trg = sorted(freq_trg.items(), key=operator.itemgetter(1), reverse = True)\n",
    "# sorted_freq_pairs = sorted(freq_pairs.items(), key=operator.itemgetter(1), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_total = 0\n",
    "for _, freq in freq_src.iteritems():\n",
    "    src_total += freq\n",
    "    \n",
    "trg_total = 0\n",
    "for _, freq in freq_trg.iteritems():\n",
    "    trg_total += freq\n",
    "    \n",
    "pairs_total = 0\n",
    "for _, freq in freq_pairs.iteritems():\n",
    "    pairs_total += freq\n",
    "\n",
    "print(\"#en phrases: %d\"%(src_total))\n",
    "print(\"#de phrases: %d\"%(trg_total))\n",
    "print(\"#(en,de) phrases: %d\"%(pairs_total))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for phrase_pair, freq in freq_pairs.iteritems():\n",
    "    p_src_trg = 1.0 * freq / freq_trg[phrase_pair[0]]\n",
    "    p_trg_src = 1.0 * freq / freq_src[phrase_pair[1]]\n",
    "    \n",
    "    freq_pairs[phrase_pair] = [freq, p_src_trg, p_trg_src]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = freq_pairs.keys()[:5]\n",
    "\n",
    "for key in keys:\n",
    "    print(key[0], '|' , key[1], ':', freq_pairs[key])\n",
    "    print(freq_trg[key[0]])\n",
    "    print(freq_src[key[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(\"data/joined_freq_pairs_all\", 'wb') as file:\n",
    "    pickle.dump(freq_pairs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "a = 3\n",
    "l = [3, 5]\n",
    "print(a is list)\n",
    "print(type(l) is list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(\"data/freq_pairs_small\", 'rb') as file:\n",
    "    freq_pairs_small = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('und verz\\xc3\\xb6gern', 'for prestige and rivalry among the various nations .') 1\n",
      "('bei der ausarbeitung', 'responsible for preparing') 1\n",
      "('( 1999 ) 410 - c5 - 0010 / 2000 - 2000 / 2004 ( cos )) , das europ\\xc3\\xa4ische parlament , den wirtschafts - und sozialausschu\\xc3\\x9f und den ausschu\\xc3\\x9f der regionen : transeurop\\xc3\\xa4ische netze - jahresbericht 1998 - gem\\xc3\\xa4\\xc3\\x9f artikel 16 der verordnung ( eg ) nr . 2236 / 95 \\xc3\\xbcber die grundregeln f\\xc3\\xbcr', '( 1999 ) 410 - c5 - 0010 / 2000 - 2000 / 2004 ( cos ) ] , the european parliament , the economic and social committee and the committee of the regions : trans - european networks 1998 annual report pursuant to article 16 of regulation ( ec ) no 2236 / 95 laying down general rules for the granting of community financial assistance in the field of trans -') 1\n",
      "('ich bin \\xc3\\xbcberzeugt , da\\xc3\\x9f die irakische regierung bereit w\\xc3\\xa4re , die resolution 1284 zu akzeptieren', 'i am sure that the iraqi government is prepared to accept resolution 1284') 1\n",
      "('und ich kann mir wirklich keinen reim darauf machen', 'and i really fail to grasp') 1\n",
      "('gratulieren', 'offer my congratulations') 1\n",
      "('wir reagieren m\\xc3\\xbcssen , k\\xc3\\xb6nnen verhindert werden', 'we must react can be prevented') 1\n",
      "('deshalb mu\\xc3\\x9f man genau darlegen , da\\xc3\\x9f die beihilferegelungen den verbrauchern lebensmittel zu preisen garantieren , die wegen der', 'is , therefore , also important to make it clear that the subsidy arrangements ensure that consumers obtain food at prices which , as a result of the') 1\n",
      "('albanische patienten schwierigkeiten haben , ins krankenhaus aufgenommen zu werden , sondern da\\xc3\\x9f albanisches personal schwierigkeiten hat , dort zu arbeiten -', 'of albanian patients having difficulty getting to hospital , albanian staff have had difficulty working there -') 1\n",
      "('wir diese regionale dimension in unsere informationspolitik einbeziehen m\\xc3\\xbcssen , und ich werde in den diskussionen mit den verantwortlichen nationalen politikern darauf achten , da\\xc3\\x9f dies eingehalten wird .', 'we must integrate this regional dimension into our information policy and , when i discuss the issue with the competent national politicians , i will ensure that this is taken into account .') 1\n"
     ]
    }
   ],
   "source": [
    "for key in old_freq_pairs.keys()[10:20]:\n",
    "    print(key, old_freq_pairs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8966987"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(old_freq_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2624229"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freq_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2800861"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freq_pairs_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('zu', 'zollen', ',', 'die', 'sich', 'f\\xc3\\xbcr', 'einen', 'fortbestand'), ('are', 'working', 'to', 'safeguard')) 1\n",
      "(('schon',), ('already', 'been', 'raised')) 1\n",
      "(('w\\xc3\\xa4hrend', 'der', 'portugiesischen', 'ratspr\\xc3\\xa4sidentschaft', 'vorangetrieben'), ('promoted', 'during', 'the', 'portuguese', 'presidency')) 1\n",
      "(('vorbereitet', 'habe'), ('have', 'already')) 1\n",
      "(('hunger', 'und', 'd\\xc3\\xbcrre', 'aufmerksam', 'machen'), ('starvation', 'and', 'drought')) 1\n",
      "(('h\\xc3\\xa4tte', 'ich', 'vielleicht'), ('i', 'might')) 1\n",
      "(('auch', 'selbst'), ('also', 'hold')) 1\n",
      "(('tun', 'es', 'nicht'), ('do', 'not')) 1\n",
      "(('diskussion',), ('discussion', 'may', 'make')) 1\n",
      "(('aus', 'dieser', 'umweltkatastrophe', 'heraus'), ('this', 'ecological', 'disaster')) 1\n"
     ]
    }
   ],
   "source": [
    "for key in freq_pairs_small.keys()[10:20]:\n",
    "    print(key, freq_pairs_small[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, [(0, 0), (1, 2), (2, 3), (3, 3)]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_pairs[\" \".join(['zu', 'zollen', ',', 'die', 'sich', 'f\\xc3\\xbcr', 'einen', 'fortbestand']), \" \".join(('are', 'working', 'to', 'safeguard'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, [(0, 0), (1, 2), (2, 3), (3, 3)]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_pairs[\" \".join([ 'sich', 'f\\xc3\\xbcr', 'einen', 'fortbestand']), \" \".join(('are', 'working', 'to', 'safeguard'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
