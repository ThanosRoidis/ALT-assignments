{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import time\n",
    "import pickle\n",
    "import operator\n",
    "from __future__ import print_function\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_file(filepath):\n",
    "    \"\"\"Reads a file into a list of phrases. Each phrase in the file must be separated with a new line character '\\n' \n",
    "    Args:\n",
    "        filepath (str): the relevant filepath of the file\n",
    "    Returns:\n",
    "        phrases (list(str)): A list with all the phrases \n",
    "    \"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        phrases = f.readlines()\n",
    "    return phrases\n",
    "\n",
    "src_file = load_file('data/file.de')\n",
    "trg_file = load_file('data/file.en')\n",
    "aligned_file = load_file('data/file.aligned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def add_freq_dict(dictionary, key, value):\n",
    "    \"\"\"Increases the frequency of an phrase/item in the dictionary by 1, or adds it with a frequency of 1 if it doesn't exist yet\n",
    "    Args:\n",
    "        dictionary (dict): a dictionary that holds the frequency of an a phrase (item)\n",
    "        item (str): a string whose frequency will be increased\n",
    "    \"\"\"\n",
    "    if key in dictionary:\n",
    "            dictionary[key][0] = [x+y for x,y in zip(dictionary[key][0] , value[0])]\n",
    "            dictionary[key][1] = [x+y for x,y in zip(dictionary[key][1] , value[1])]\n",
    "    else:\n",
    "        dictionary[key] = value\n",
    "\n",
    "\n",
    "def extract(trg_start, trg_end, src_start, src_end, alignments, trg_aligned, trg_len):    \n",
    "    \"\"\" Checks if the subphrases of the source and target language are a consisnte pair, \n",
    "        assuming that no word in the source language is aligned with a word of the target language  outside the boundaries\n",
    "    Args:\n",
    "        trg_start (int): The target subphrase's first word position\n",
    "        trg_end (int): The target subphrase's last word position\n",
    "        src_start (int): The source subphrase's first word position\n",
    "        src_end (int): The source subphrase's last word position\n",
    "        alignments (list(tuple(int))): The alignment between the \n",
    "        trg_aligned (set(str)): A set with all the target language words that are aligned with at least one source word \n",
    "        trg_len (int): The number of words of the target language phrase\n",
    "        \n",
    "    Returns:\n",
    "        E (list(tuple(str))): A list with all of the extracted phrase pairs (f,e). This is the base (f,e) specified by the arguement and pairs that have a words appended on 'e' that are unaligned \n",
    "        A (list(list(tuple(int)))): A list with the alignment of the respective pair at E (A[i] has the alignments of E[i]) \n",
    "\n",
    "    \"\"\"\n",
    "    if trg_end < 0 :\n",
    "        return [], []\n",
    "    \n",
    "    A = []\n",
    "    \n",
    "    a = []\n",
    "    \n",
    "    for trg_word, src_word  in alignments:\n",
    "        if trg_start <= trg_word <= trg_end:\n",
    "            \n",
    "            if (src_word < src_start or src_word > src_end):  \n",
    "                return [], []\n",
    "            else:\n",
    "                \n",
    "                a.append((trg_word - trg_start, src_word - src_start))\n",
    "\n",
    "    E = []\n",
    "    trg_s = trg_start\n",
    "    \n",
    "    while True:\n",
    "        trg_e = trg_end\n",
    "        while True:\n",
    "            E.append([src_start, src_end, trg_s, trg_e])\n",
    "            \n",
    "            A.append(a)\n",
    "             \n",
    "            return E, A\n",
    "            trg_e += 1\n",
    "            \n",
    "            if trg_e in trg_aligned or trg_e == len(trg_words):\n",
    "                break \n",
    "\n",
    "        trg_s -= 1\n",
    "        \n",
    "        if trg_s in trg_aligned or trg_s < 0:\n",
    "            break\n",
    "            \n",
    "        # if an unaligned word was added at the beginning, increase the alignments positions by 1 \n",
    "       \n",
    "        a = [(i[0]+1,i[1]) for i in a]\n",
    "        \n",
    "    return E, A\n",
    "\n",
    "\n",
    "def extract_phrases(src_words, trg_words, alignments, cutoff):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        src_words (list(str)):\n",
    "        trg_words (list(str)):\n",
    "        alignments (list(tuple(int))):\n",
    "        cutoff (int): \n",
    "        \n",
    "    Returns:\n",
    "        extracted_phrases (list(tuple(str))):\n",
    "        extracted_alignments (list(tuple(int))):\n",
    "    \"\"\"\n",
    "    \n",
    "    if cutoff == -1:\n",
    "        cutoff = len(src_words)\n",
    "        \n",
    "        \n",
    "    trg_aligned = set()\n",
    "    for (trg,_) in alignments:\n",
    "        trg_aligned.add(trg)\n",
    "    \n",
    "    \n",
    "    extracted_phrases = []\n",
    "    extracted_alignments = []\n",
    "    # for every possible \n",
    "    for src_start in range(len(src_words)):\n",
    "        for src_end in range(src_start, min(src_start + cutoff, len(src_words))):\n",
    "\n",
    "            #Find the min and max position of the target words that the source phrase is aligned to\n",
    "            trg_start = len(trg_words) - 1\n",
    "            trg_end = - 1\n",
    "            for  (trg,src) in alignments: \n",
    "                if src_start <= src <= src_end:\n",
    "                    trg_start = min(trg, trg_start)\n",
    "                    trg_end = max(trg, trg_end)\n",
    "                    \n",
    "            \n",
    "            if(trg_end - trg_start > cutoff - 1):\n",
    "                continue\n",
    "\n",
    "            phrase_pairs, A = extract(trg_start, trg_end, src_start, src_end, alignments, trg_aligned, len(trg_words))\n",
    "            \n",
    "            if (phrase_pairs):\n",
    "                extracted_phrases.extend(phrase_pairs)\n",
    "                for a in A:\n",
    "                    extracted_alignments.append(a);\n",
    "            \n",
    "    return extracted_phrases, extracted_alignments\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def count_reorderings(src_words, trg_words, A, word_based = False):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    temp = {}\n",
    "    \n",
    "    pp, _ = extract_phrases(src_words, trg_words, A, 7)\n",
    "    \n",
    "    if word_based:\n",
    "        next_iterator = A\n",
    "    else:\n",
    "        next_iterator = pp\n",
    "\n",
    "    for phrase1  in pp:\n",
    "        [src_s, src_e, trg_s, trg_e] = phrase1\n",
    "        \n",
    "        m, s, dr, dl = 0,0,0,0 #left-to-right reordering counters\n",
    "        m2, s2, dr2, dl2 = 0,0,0,0 #right-to-left reordering counters\n",
    "\n",
    "        for a in next_iterator:\n",
    "            \n",
    "            if word_based:\n",
    "                [next_src_s, next_src_e, next_trg_s, next_trg_e] = [a[1], a[1], a[0], a[0]]\n",
    "            else:\n",
    "                [next_src_s, next_src_e, next_trg_s, next_trg_e] = a\n",
    "                \n",
    "                \n",
    "\n",
    "            # left to right\n",
    "            #if it is the next word, check if monotone/swap/discontinues to the right\n",
    "            if next_trg_s == trg_e + 1:\n",
    "                if next_src_s == src_e + 1:\n",
    "                    m+=1\n",
    "                elif src_s == next_src_e + 1:\n",
    "                    s+=1\n",
    "                else: \n",
    "                    if next_src_s > src_e:\n",
    "                        dr += 1\n",
    "                    elif next_src_e < src_s:\n",
    "                        dl +=1\n",
    "\n",
    "            # right to left \n",
    "             #if it is the next word, check if monotone/swap/discontinues to the right\n",
    "            if  next_trg_e == trg_s - 1:\n",
    "                if next_src_e == src_s - 1:\n",
    "                    m2+=1\n",
    "                elif next_src_s == src_e + 1:\n",
    "                    s2+=1\n",
    "                else:\n",
    "                    if next_src_s > src_e:\n",
    "                        dl2 += 1\n",
    "                    elif next_src_e < src_s:\n",
    "                        dr2 += 1\n",
    "\n",
    "\n",
    "        pair = (\" \".join(trg_words[trg_s:trg_e+1]) , \" \".join(src_words[src_s:src_e+1]))        \n",
    "\n",
    "        add_freq_dict(temp, pair, [[m,s,dr,dl] , [m2,s2,dr2,dl2]])\n",
    "\n",
    "    \n",
    "    return temp\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 / 50000 (110s)                                                                                               \n",
      "Done!!!\n",
      "Total duration: 110s\n",
      "#unique en phrases: 2277463\n"
     ]
    }
   ],
   "source": [
    "phrase_pairs = dict() \n",
    "\n",
    "start_time = time.time()\n",
    "    \n",
    "for i in range(len(src_file)):\n",
    "    src_words = src_file[i].split()\n",
    "    trg_words = trg_file[i].split()        \n",
    "    alignments = [[int(a) for a in alignment.split('-')] for alignment in aligned_file[i].split()] #convert to list of int pairs\n",
    "    alignments = [(al[1], al[0]) for al in alignments] #reverse their order so that they are (trg,src) instead of (src,trg)\n",
    "    \n",
    "    this_phrase_pairs = count_reorderings(src_words, trg_words, alignments)\n",
    "    \n",
    "    for key,value in this_phrase_pairs.items():\n",
    "        add_freq_dict(phrase_pairs, key, value)\n",
    "        \n",
    "    #show real time progress\n",
    "    if ((i+1) % (len(src_file) / 100) == 0):\n",
    "        print(' \\r%d / %d (%ds)'%(i+1,len(src_file), time.time() - start_time), end = '')\n",
    "\n",
    "print()\n",
    "print('Done!!!')\n",
    "print('Total duration: %ds'%(time.time() - start_time))\n",
    "\n",
    "print(\"#unique en phrases: %d\"%(len(phrase_pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in phrase_pairs.keys()[10:20]:\n",
    "    print(key, phrase_pairs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/reordering_pairs_phrase.pkl', 'wb') as file:\n",
    "    pickle.dump(phrase_pairs, file)\n",
    "\n",
    "# with open('data/reordering_pairs_phrase.pkl', 'rb') as file:\n",
    "#     phrase_pairs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert counts to probabilities\n",
    "for key, value in phrase_pairs.items():\n",
    "    \n",
    "    sum_ = numpy.sum(value[0])\n",
    "    if sum_ > 0:\n",
    "        for i in range(4):\n",
    "            phrase_pairs[key][0][i] /= 1.0 * sum_\n",
    "\n",
    "    sum_ = numpy.sum(value[1])\n",
    "    if sum_ > 0:\n",
    "        for i in range(4):\n",
    "            phrase_pairs[key][1][i] /= 1.0* sum_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('in its relations with the', 'in seinen beziehungen zu den') [[0.2, 0.0, 0.8, 0.0], [0.0, 0.0, 0.0, 1.0]]\n",
      "('be tackled separately', 'gesonderter form durchgef\\xc3\\xbchrt werden') [[0, 0, 0, 0], [0.0, 1.0, 0.0, 0.0]]\n",
      "('other relevant', 'weitere zweckm\\xc3\\xa4\\xc3\\x9fige') [[1.0, 0.0, 0.0, 0.0], [0, 0, 0, 0]]\n",
      "('even', 'auch dann') [[0.0, 0.0, 0.0, 1.0], [0.0, 0.25, 0.75, 0.0]]\n",
      "('a strong voice in', 'einer starken stimme in') [[1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]]\n",
      "('is dependent on aid , as', 'auf f\\xc3\\xb6rderungen angewiesen ist , da') [[1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]]\n",
      "('key aspects', 'wesentliche aspekte') [[0, 0, 0, 0], [1.0, 0.0, 0.0, 0.0]]\n",
      "('the duty', 'die aufgabe') [[1.0, 0.0, 0.0, 0.0], [1.0, 0.0, 0.0, 0.0]]\n",
      "('social protection', 'ausreichenden sozialschutz') [[0.0, 0.0, 0.0, 1.0], [0.5, 0.0, 0.5, 0.0]]\n",
      "('guarantee that', 'es garantien gibt , da\\xc3\\x9f') [[0.18181818181818182, 0.0, 0.0, 0.8181818181818182], [0.25, 0.0, 0.75, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "for key in phrase_pairs.keys()[10:20]:\n",
    "    print(key, phrase_pairs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en = \"Peter has scored a goal .\"\n",
    "# de = \"Peter hat ein Tor geschossen .\"\n",
    "# A = \"0-0 1-1 4-2 2-3 3-4 5-5\"\n",
    "# A = [[int(a) for a in alignment.split('-')] for alignment in A.split()] #convert to list of int pairs \n",
    "# src_words = de.split();\n",
    "# trg_words = en.split();\n",
    "# alignment_matrix = numpy.zeros((len(src_words),len(trg_words)), dtype=int)\n",
    "# n = len(src_words) - 1;\n",
    "# for (i,j) in A: \n",
    "#     alignment_matrix[n - i,j] = 1\n",
    "\n",
    "\n",
    "# A = [(al[1], al[0]) for al in A] #reverse their order so that they are (trg,src) instead of (src,trg)\n",
    "   \n",
    "# phrase_pairs = {}\n",
    "    \n",
    "# this_phrase_pairs = count_reorderings(src_words, trg_words, A, False)\n",
    "\n",
    "# for key, value in this_phrase_pairs.items():\n",
    "#     add_freq_dict(phrase_pairs, key, value)\n",
    "\n",
    "\n",
    "# print(alignment_matrix) \n",
    "# display(phrase_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phrase_pairs = dict() \n",
    "\n",
    "start_time = time.time()\n",
    "    \n",
    "for i in range(len(src_file)):\n",
    "    src_words = src_file[i].split()\n",
    "    trg_words = trg_file[i].split()        \n",
    "    alignments = [[int(a) for a in alignment.split('-')] for alignment in aligned_file[i].split()] #convert to list of int pairs\n",
    "    alignments = [(al[1], al[0]) for al in alignments] #reverse their order so that they are (trg,src) instead of (src,trg)\n",
    "    \n",
    "    pp, pp_a = extract_phrases(src_words, trg_words, alignments, 7)\n",
    "    \n",
    "    for (phrase, phrase_alignments) in zip(pp,a):\n",
    "        phrase_src_words = src_words[phrase[0] : phrase[1] + 1]\n",
    "        phrase_trg_words = trg_words[phrase[2] : phrase[3] + 1]\n",
    "        \n",
    "        this_phrase_pairs = count_reorderings(phrase_src_words, phrase_trg_words, phrase_alignments)\n",
    "    \n",
    "        for key,value in this_phrase_pairs.items():\n",
    "            add_freq_dict(phrase_pairs, key, value)\n",
    "\n",
    "    #show real time progress\n",
    "    if ((i+1) % (len(src_file) / 100) == 0):\n",
    "        print(' \\r%d / %d (%ds)'%(i+1,len(src_file), time.time() - start_time), end = '')\n",
    "\n",
    "print()\n",
    "print('Done!!!')\n",
    "print('Total duration: %ds'%(time.time() - start_time))\n",
    "\n",
    "print(\"#unique en phrases: %d\"%(len(phrase_pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4]\n",
    "\n",
    "a[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
