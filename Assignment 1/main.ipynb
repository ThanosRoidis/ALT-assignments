{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import time\n",
    "import pickle\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_freq_dict(dictionary, item):\n",
    "    if item in dictionary:\n",
    "        dictionary[item] += 1\n",
    "    else:\n",
    "        dictionary[item] = 1\n",
    "\n",
    "        \n",
    "def load_file(filepath):\n",
    "    \n",
    "    with open(filepath, 'r') as f:\n",
    "        file = f.readlines()\n",
    "    return file\n",
    "\n",
    "src_file = load_file('data/file.en')\n",
    "trg_file = load_file('data/file.de')\n",
    "aligned_file = load_file('data/file.aligned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract(trg_start, trg_end, src_start, src_end, alignments, trg_aligned, trg_len):    \n",
    "  \n",
    "\n",
    "    if trg_end < 0 :\n",
    "        return []\n",
    "    \n",
    "    a = []\n",
    "    \n",
    "    for trg_word, src_word  in alignments:\n",
    "        if ((trg_start <= trg_word <= trg_end) and \n",
    "           (src_word < src_start or src_word > src_end)):  \n",
    "            return []\n",
    "        else:\n",
    "            a.append( (trg_word - trg_start, src_word - src_start) )\n",
    "            \n",
    "        \n",
    "    E = []\n",
    "    trg_s = trg_start\n",
    "    \n",
    "    while True:\n",
    "        trg_e = trg_end\n",
    "        while True:\n",
    "            E.append( (tuple(trg_words[trg_s:trg_e+1]) , tuple(src_words[src_start:src_end+1])) )\n",
    "            \n",
    "            trg_e += 1\n",
    "            \n",
    "            if trg_e in trg_aligned or trg_e == len(trg_words):\n",
    "                break \n",
    "    \n",
    "        trg_s -= 1\n",
    "        \n",
    "        if trg_s in trg_aligned or trg_s < 0:\n",
    "            break\n",
    "    return E, a\n",
    "\n",
    "\n",
    "def extract_phrases(src_words, trg_words, alignments, cutoff):\n",
    "    \n",
    "    \n",
    "    if cutoff == -1:\n",
    "        cutoff = len(src_words)\n",
    "        \n",
    "        \n",
    "    trg_aligned = set()\n",
    "    for (trg,_) in alignments:\n",
    "        trg_aligned.add(trg)\n",
    "    \n",
    "    \n",
    "    extracted_phrases = []\n",
    "    for src_start in range(len(src_words)):\n",
    "        for src_end in range(src_start, min(src_start + cutoff, len(src_words))):\n",
    "\n",
    "            trg_start = len(trg_words) - 1\n",
    "            trg_end = - 1\n",
    "            for  (trg,src) in alignments: \n",
    "                if src_start <= src <= src_end:\n",
    "                    trg_start = min(trg, trg_start)\n",
    "                    trg_end = max(trg, trg_end)\n",
    "                    \n",
    "            \n",
    "            if(trg_end - trg_start > cutoff - 1):\n",
    "                continue\n",
    "\n",
    "            phrase_pairs, a = extract(trg_start, trg_end, src_start, src_end, alignments, trg_aligned, len(trg_words))\n",
    "            if (phrase_pairs):\n",
    "                extracted_phrases.extend(phrase_pairs)\n",
    "            \n",
    "    return extracted_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('asd', 'asdsd')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# src_words = \"michael assumes that he will stay in the house\".split()\n",
    "# trg_words = \"michael geht davon aus , dass er im haus bleibt\".split()\n",
    "# alignments = [(0,0), (1,1), (2,1), (3,1), (5,2), (6,3), (9,4), (9,5), (7,6), (7,7), (8,8)]\n",
    " \n",
    "# BP = extract_phrases(src_words, trg_words, alignments)\n",
    "    \n",
    "# freq_pairs = dict()\n",
    "# freq_src = dict()\n",
    "# freq_trg = dict()\n",
    "    \n",
    "# for pair in BP:\n",
    "#     add_freq_dict(freq_pairs,pair)\n",
    "#     add_freq_dict(freq_trg, pair[0])\n",
    "#     add_freq_dict(freq_src, pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 / 50000 (135s)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      "Done!!!\n",
      "Total duration: 135s\n",
      "#en phrases: 1189230\n",
      "#de phrases: 1386442\n",
      "#(en,de) phrases: 2624229\n"
     ]
    }
   ],
   "source": [
    "freq_pairs = dict()\n",
    "freq_src = dict()\n",
    "freq_trg = dict()\n",
    "    \n",
    "start_time = time.time()\n",
    "    \n",
    "for i in range(len(src_file)):\n",
    "    src_words = src_file[i].split()\n",
    "    trg_words = trg_file[i].split()        \n",
    "    alignments = [[int(a) for a in alignment.split('-')] for alignment in aligned_file[i].split()]\n",
    "    \n",
    "    BP = extract_phrases(src_words, trg_words, alignments, 5)\n",
    "    \n",
    "    for pair in BP:\n",
    "        add_freq_dict(freq_pairs,pair)\n",
    "        add_freq_dict(freq_trg, pair[0])\n",
    "        add_freq_dict(freq_src, pair[1])\n",
    "        \n",
    "    print(' \\r%d / %d (%ds)'%(i+1,len(src_file), time.time() - start_time), end = '')\n",
    "\n",
    "print()\n",
    "print('Done!!!')\n",
    "print('Total duration: %ds'%(time.time() - start_time))\n",
    "\n",
    "print(\"#en phrases: %d\"%(len(freq_src)))\n",
    "print(\"#de phrases: %d\"%(len(freq_trg)))\n",
    "print(\"#(en,de) phrases: %d\"%(len(freq_pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('ausgegeben', ',', 'um', 'die', 'natur', 'zu', 'sch\\xc3\\xa4digen', '.'), ('to', 'damage', 'the', 'countryside', '.')) 1\n",
      "(('rede', ',', 'sondern', 'auch', 'von', 'rechten'), ('but', 'also', 'of', 'rights')) 1\n",
      "(('gef\\xc3\\xa4hrlichen', 'autowracks', 'verschandelt', 'werden', ','), ('dangerous', 'wrecks', ',', 'inhabited')) 1\n",
      "(('der', 'kriminalit\\xc3\\xa4t', 'an', 'die', 'hand'), ('crime',)) 1\n",
      "(('position', 'bezogen', '.'), ('.',)) 1\n",
      "(('bev\\xc3\\xb6lkerung', 'sind', 'analphabeten'), ('africans', 'are', 'illiterate')) 1\n",
      "(('was', 'sind'), ('what', ',')) 1\n",
      "(('handeln', 'bereit', 'sein'), ('be', 'prepared', 'to', 'act')) 1\n",
      "(('0265', '/', '1999', '-', '1999'), ('0265', '/', '1999', '-', '1999')) 3\n",
      "(('wir', 'wollen', 'daran'), ('so',)) 1\n"
     ]
    }
   ],
   "source": [
    "for key in freq_pairs.keys()[:10]:\n",
    "    print(key, freq_pairs[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq_pairs = dict()\n",
    "freq_src = dict()\n",
    "freq_trg = dict()\n",
    "    \n",
    "start_time = time.time()\n",
    "    \n",
    "for i in range(len(src_file)):\n",
    "    src_words = src_file[i].split()\n",
    "    trg_words = trg_file[i].split()        \n",
    "    alignments = [[int(a) for a in alignment.split('-')] for alignment in aligned_file[i].split()]\n",
    "    \n",
    "    BP = extract_phrases(src_words, trg_words, alignments)\n",
    "    \n",
    "    for pair in BP:\n",
    "        add_freq_dict(freq_pairs,pair)\n",
    "        add_freq_dict(freq_trg, pair[0])\n",
    "        add_freq_dict(freq_src, pair[1])\n",
    "        \n",
    "    print(' \\r%d / %d (%ds)'%(i+1,len(src_file), time.time() - start_time), end = '')\n",
    "\n",
    "print()\n",
    "print('Done!!!')\n",
    "print('Total duration: %ds'%(time.time() - start_time))\n",
    "\n",
    "print(\"#en phrases: %d\"%(len(freq_src)))\n",
    "print(\"#de phrases: %d\"%(len(freq_trg)))\n",
    "print(\"#(en,de) phrases: %d\"%(len(freq_pairs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save files\n",
    "# with open(\"data/freq_src_small\", 'wb') as file:\n",
    "#     pickle.dump(freq_src, file)\n",
    "\n",
    "# with open(\"data/freq_trg_small\", 'wb') as file:\n",
    "#     pickle.dump(freq_trg, file)\n",
    "\n",
    "# with open(\"data/freq_pairs_small\", 'wb') as file:\n",
    "#     pickle.dump(freq_pairs, file)\n",
    "\n",
    "with open(\"data/joined_freq_src\", 'rb') as file:\n",
    "    freq_src = pickle.load(file)\n",
    "\n",
    "with open(\"data/joined_freq_trg\", 'rb') as file:\n",
    "    freq_trg = pickle.load(file)\n",
    "\n",
    "with open(\"data/joined_freq_pairs\", 'rb') as file:\n",
    "    freq_pairs = pickle.load(file)\n",
    "        \n",
    "print(\"#en phrases: %d\"%(len(freq_src)))\n",
    "print(\"#de phrases: %d\"%(len(freq_trg)))\n",
    "print(\"#(en,de) phrases: %d\"%(len(freq_pairs)))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import operator\n",
    "# sorted_freq_src = sorted(freq_src.items(), key=operator.itemgetter(1), reverse = True)\n",
    "# sorted_freq_trg = sorted(freq_trg.items(), key=operator.itemgetter(1), reverse = True)\n",
    "# sorted_freq_pairs = sorted(freq_pairs.items(), key=operator.itemgetter(1), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_total = 0\n",
    "for _, freq in freq_src.iteritems():\n",
    "    src_total += freq\n",
    "    \n",
    "trg_total = 0\n",
    "for _, freq in freq_trg.iteritems():\n",
    "    trg_total += freq\n",
    "    \n",
    "pairs_total = 0\n",
    "for _, freq in freq_pairs.iteritems():\n",
    "    pairs_total += freq\n",
    "\n",
    "print(\"#en phrases: %d\"%(src_total))\n",
    "print(\"#de phrases: %d\"%(trg_total))\n",
    "print(\"#(en,de) phrases: %d\"%(pairs_total))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for phrase_pair, freq in freq_pairs.iteritems():\n",
    "    p_src_trg = 1.0 * freq / freq_trg[phrase_pair[0]]\n",
    "    p_trg_src = 1.0 * freq / freq_src[phrase_pair[1]]\n",
    "    \n",
    "    freq_pairs[phrase_pair] = [freq, p_src_trg, p_trg_src]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keys = freq_pairs.keys()[:5]\n",
    "\n",
    "for key in keys:\n",
    "    print(key[0], '|' , key[1], ':', freq_pairs[key])\n",
    "    print(freq_trg[key[0]])\n",
    "    print(freq_src[key[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(\"data/joined_freq_pairs_all\", 'wb') as file:\n",
    "    pickle.dump(freq_pairs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
